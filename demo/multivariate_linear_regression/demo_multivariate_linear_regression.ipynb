{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate linear regression\n",
    "\n",
    "\n",
    "In this notebook, we will make use of the multivariate linear regression to predict the price of houses. We will use the Boston house price dataset available at https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html for our purpose. The dataset includes 14 attributes per house and its price. Some examples of the attributes are:\n",
    "\n",
    "|  Attribute       | Definition    | \n",
    "| :-------------:  | :-------------:| \n",
    "| CRIM             | per capita crime rate by town |\n",
    "| ZN               | proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
    "| INDUS            | proportion of non-retail business acres per town. |\n",
    "| NOX              | nitric oxides concentration (parts per 10 million) |\n",
    "| RM               | average number of rooms per dwelling |\n",
    "| DIS              | weighted distances to five Boston employment centres |\n",
    "| RAD              | index of accessibility to radial highways |\n",
    "| TAX              | full-value property-tax rate per \\$10,000 |\n",
    "| PTRATIO          | pupil-teacher ratio by town |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "boston_data = np.load('data/boston_house_price.npz')\n",
    "X_train = boston_data['X']\n",
    "y_train = boston_data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution of the linear regression can be written as \n",
    "\\begin{align}\n",
    "\\mathbf{w} = \\mathbf{X}^{+}\\mathbf{y}\\;,\n",
    "\\end{align}\n",
    "where $\\mathbf{X}^{+}$ is the pseudoinverse of $\\mathbf{X}$. \n",
    "Recall that $\\mathbf{X}$ is a matrix where each row is one sample and $\\boldsymbol{y}$\n",
    "is a vector of target values.\n",
    "\n",
    "\n",
    "\n",
    "Using the Numpy pseudoinverse function, we will define a \n",
    "function to fit a linear regression model to our data. \n",
    "If we need to add a bias, we csan simply augment our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LinearRegression(X, y, bias=True):\n",
    "\n",
    "    # Insert constant ones for bias weights\n",
    "    if (bias):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    w = np.linalg.pinv(X).dot(y)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define another function for prediction $\\hat{y} = \\mathbf{w}^\\top\\mathbf{x}$. Our function below will also compute the mean square error defined as\n",
    "\\begin{align}\n",
    "\\mathcal{L}_{SE} = \\frac{1}{m} \\sum_{i=1}^m \\|y_i - \\hat{y}_i\\|^2\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_LinearRegression(w,X, y, bias=True):\n",
    "\n",
    "    # Insert constant ones for bias weights\n",
    "    \n",
    "    if (bias):\n",
    "        b_star = w[0]  #recall that with bias, we put the bias into teh first element of w (index = 0) \n",
    "        w_star = w[1:] \n",
    "        y_hat = X.dot(w_star) + b_star\n",
    "    else:\n",
    "        y_hat = X.dot(w)\n",
    "            \n",
    "    \n",
    "    mse = np.mean(np.square(y-y_hat))\n",
    "    return y_hat, mse    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit a linear model without bias and evaluate it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = fit_LinearRegression(X_train, y_train, bias=False)\n",
    "y_hat1, mse1 = predict_LinearRegression(w1,X_train, y_train, bias=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit a linear model with bias and evaluate it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error: without bias -> 24.166, with bias -> 21.895\n"
     ]
    }
   ],
   "source": [
    "w2 = fit_LinearRegression(X_train, y_train, bias=True)\n",
    "y_hat2, mse2 = predict_LinearRegression(w2,X_train, y_train, bias=True)\n",
    "print(\"Regression Error: without bias -> {0:0.3f}, with bias -> {1:0.3f}\".format(mse1,mse2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model with bias has a lower error. Let's check some of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   without bias  with bias\n",
      "0  24.0    29.098264   30.003843\n",
      "1  21.6    24.502275   25.025562\n",
      "2  34.7    31.227426   30.567597\n",
      "3  33.4    29.707104   28.607036\n",
      "4  36.2    29.564796   27.943524\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[:5], \"without bias\": y_hat1[:5], \"with bias\": y_hat2[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems that for the very first five samples, the model without bias works better. Let's check out some other samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   without bias  with bias\n",
      "0  28.7    29.098264   25.256284\n",
      "1  22.9    24.502275   23.001808\n",
      "2  27.1    31.227426   19.535988\n",
      "3  16.5    29.707104   11.523637\n",
      "4  18.9    29.564796   18.920262\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[5:10], \"without bias\": y_hat1[:5], \"with bias\": y_hat2[5:10]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, look, in some cases the model with bias does a much better job. \n",
    "Now, let us have some fun. Let us add some non-linear features to our model. The idea folows the concept of polynomial regression, check this [Wikipedia page](https://en.wikipedia.org/wiki/Polynomial_regression) for a brif inroduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error: with poly-2 features -> 14.247\n"
     ]
    }
   ],
   "source": [
    "X_quad = np.concatenate((X_train,X_train**2),axis=1)\n",
    "w3 = fit_LinearRegression(X_quad, y_train, bias=True)\n",
    "y_hat3, mse3 = predict_LinearRegression(w3,X_quad, y_train, bias=True)\n",
    "print(\"Regression Error: with poly-2 features -> {0:0.3f}\".format(mse3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y   linear features  poly-2 features\n",
      "0  24.0     30.003843        28.340697   \n",
      "1  21.6     25.025562        23.296078   \n",
      "2  34.7     30.567597        31.926581   \n",
      "3  33.4     28.607036        32.024942   \n",
      "4  36.2     27.943524        30.071343   \n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame({\"y\": y_train[:5], \"linear features\": y_hat2[:5], \"poly-2 features\": y_hat3[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we continue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Error: with poly-3 features -> 13.061\n",
      "     y   linear features  poly-3 features\n",
      "0  24.0     30.003843        28.340697   \n",
      "1  21.6     25.025562        23.296078   \n",
      "2  34.7     30.567597        31.926581   \n",
      "3  33.4     28.607036        32.024942   \n",
      "4  36.2     27.943524        30.071343   \n"
     ]
    }
   ],
   "source": [
    "X_cube = np.concatenate((X_train,X_train**2,X_train**3),axis=1)\n",
    "w4 = fit_LinearRegression(X_cube, y_train, bias=True)\n",
    "y_hat4, mse4 = predict_LinearRegression(w4,X_cube, y_train, bias=True)\n",
    "print(\"Regression Error: with poly-3 features -> {0:0.3f}\".format(mse4))\n",
    "df = pandas.DataFrame({\"y\": y_train[:5], \"linear features\": y_hat2[:5], \"poly-3 features\": y_hat3[:5]})\n",
    "pandas.set_option('colheader_justify', 'center')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the beauty is that with neural network, we will learn how to extract non-linear features that are desirable for the problem in hand (instead of engineering them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
